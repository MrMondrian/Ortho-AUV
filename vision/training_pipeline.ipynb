{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install albumentations\n",
    "!pip install opencv-python\n",
    "!pip install ultralytics\n",
    "!pip install roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir dataset\n",
    "!mkdir dataset/augmented\n",
    "!mkdir dataset/augmented/train\n",
    "!mkdir dataset/augmented/test\n",
    "!mkdir dataset/augmented/val\n",
    "!mkdir dataset/augmented/train/images\n",
    "!mkdir dataset/augmented/test/images\n",
    "!mkdir dataset/augmented/val/images\n",
    "!mkdir dataset/augmented/train/labels\n",
    "!mkdir dataset/augmented/test/labels\n",
    "!mkdir dataset/augmented/val/labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset.yaml', 'w+') as f:\n",
    "    f.write(\"train: /content/dataset/augmented/train/images\\n\")\n",
    "    f.write(\"test: /content/dataset/augmented/test/images\\n\")\n",
    "    f.write(\"val: /content/dataset/augmented/val/images\\n\")\n",
    "    f.write(\"nc: 1\\n\")\n",
    "    f.write('names: [\"Fish1\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given a list of samples, make two copies of each sample that are darker/brighter to simulate differently lit environments\n",
    "def brightnessAugment(images):\n",
    "    out = []\n",
    "    for image in images:\n",
    "        transform = A.Compose([ A.augmentations.transforms.ColorJitter (brightness=(1.05, 1.05), contrast=0, saturation=0, hue=0, always_apply=True) ])\n",
    "        bright_img = transform(image=image)[\"image\"]\n",
    "        transform = A.Compose([ A.augmentations.transforms.ColorJitter (brightness=(0.95, 0.95), contrast=0, saturation=0, hue=0, always_apply=True) ])\n",
    "        dark_img = transform(image=image)[\"image\"]\n",
    "        out.append(bright_img)\n",
    "        out.append(dark_img)\n",
    "    return out\n",
    "\n",
    "#given a list of samples, make a copy of each sample but more blurred to simulate objects out of focus, dirty lenses, and backscattering\n",
    "def blurAugment(images):\n",
    "    out = []\n",
    "    for image in images:\n",
    "        ksize = (10, 10) # lower to lower blur\n",
    "        blurred_img = cv2.blur(image, ksize)\n",
    "        out.append(blurred_img)\n",
    "    return out\n",
    "\n",
    "#given a list of samples, make a copy of each sample but with a lower contrast image to simulate backscattering and over/under-exposure\n",
    "def contrastAugment(images):\n",
    "    out = []\n",
    "    for image in images:\n",
    "        transform = A.Compose([ A.augmentations.transforms.ColorJitter (brightness=0, contrast=(0.1, 0.1), saturation=0, hue=0, always_apply=True) ])\n",
    "        decontrasted_img = transform(image=image)[\"image\"]\n",
    "        out.append(decontrasted_img)\n",
    "    return out\n",
    "\n",
    "#given a list of samples, make a copy of each sample but with camera noise added to the image to simulate different camera feeds\n",
    "def noiseAugment(images):\n",
    "    out = []\n",
    "    for image in images:\n",
    "        transform = A.Compose([ A.augmentations.transforms.ISONoise(color_shift=(0.01, 0.01), intensity=(0.8, 0.8), always_apply=True) ])\n",
    "        noisy_img = transform(image=image)[\"image\"]\n",
    "        out.append(noisy_img)\n",
    "    return out\n",
    "\n",
    "#given a list of samples, make a copy of each sample but with the image downscaled (lower resolution of image) to simulate lower quality cameras/images\n",
    "def resolutionAugment(images):\n",
    "    out = []\n",
    "    for image in images:\n",
    "        #interpolation=A.augmentations.transforms.Interpolation(downscale=cv2.INTER_NEAREST, upscale=cv2.INTER_NEAREST)\n",
    "        transform = A.Compose([ A.augmentations.transforms.Downscale(scale_min=0.25, scale_max=0.25, always_apply=True) ])\n",
    "        low_res_img = transform(image=image)[\"image\"]\n",
    "        out.append(low_res_img)\n",
    "    return out\n",
    "\n",
    "#increase intensity of blues in given image\n",
    "def make_bluer(img, color_shift_intensity):\n",
    "    img_b, img_g, img_r = cv2.split(img) #split by channel\n",
    "    img_b = np.uint16(img_b)\n",
    "    img_b += color_shift_intensity\n",
    "    np.clip(img_b, 0, 255, out=img_b)\n",
    "    img_b = np.uint8(img_b)\n",
    "    img = cv2.merge((img_b, img_g, img_r)) #merge adjusted channels\n",
    "    del img_b\n",
    "    del img_g\n",
    "    del img_r\n",
    "    return img\n",
    "\n",
    "#increase intensity of greens in given image\n",
    "def make_greener(img, color_shift_intensity):\n",
    "    img_b, img_g, img_r = cv2.split(img) #split by channel\n",
    "    img_g = np.uint16(img_g)\n",
    "    img_g += color_shift_intensity\n",
    "    np.clip(img_g, 0, 255, out=img_g)\n",
    "    img_g = np.uint8(img_g)\n",
    "    img = cv2.merge((img_b, img_g, img_r)) #merge adjusted channels\n",
    "    del img_b\n",
    "    del img_g\n",
    "    del img_r\n",
    "    return img\n",
    "\n",
    "#given a list of samples, make two copies of each sample (one bluer, one greener) to simulate different pools + color attenuation\n",
    "def colorAugment(images):\n",
    "    out = []\n",
    "    color_shift_intensity = int(255*0.1)\n",
    "    for image in images:\n",
    "        blue_img = make_bluer(image, color_shift_intensity)\n",
    "        green_img = make_greener(image, color_shift_intensity)\n",
    "        out.append(blue_img)\n",
    "        out.append(green_img)\n",
    "    return out\n",
    "\n",
    "#remove all files/folders in folder\n",
    "def clearFolder(folder):\n",
    "    #get all directory/filenames in folder\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                #delete all files\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                #recursively delete everything in sub-folders\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "\n",
    "#output given samples to given folder so that each image has corresponding label with same filename in /images and /labels subfolders respectively\n",
    "def sendToFolders(samples, output_folder):\n",
    "    #remove all files/folders in output folders\n",
    "    clearFolder(output_folder + \"/images\")\n",
    "    clearFolder(output_folder + \"/labels\")\n",
    "    instance_count = 0 #keep track of instance count for filename\n",
    "    for sample in samples:\n",
    "        image, label = sample\n",
    "        #write image to file in /images\n",
    "        cv2.imwrite(output_folder + '/images/img' + str(instance_count) + '.png', image)\n",
    "        #write label to file in /labels\n",
    "        with open(output_folder + '/labels/img' + str(instance_count) + '.txt', 'w+') as f:\n",
    "            #each box gets its own line\n",
    "            for box in label:\n",
    "                f.write(box)\n",
    "        instance_count += 1\n",
    "\n",
    "#given array of image/label arrays, and an integer of how to split the data, returns the dataset split accordingly\n",
    "def splitData(samples, splits):\n",
    "    #for now we just shuffle the data to hopefully get a similar sample size\n",
    "    # of images for every class in the train, test and val splits\n",
    "    #ideally in the future we should split by class and then combine together to make sure the datasets are balanced\n",
    "\n",
    "    #shuffle data\n",
    "    random.shuffle(samples)\n",
    "    #get indices for split\n",
    "    splits = [int(len(samples)*s) for s in splits]\n",
    "    #return split data\n",
    "    return samples[:splits[0]], samples[splits[0]:splits[0]+splits[1]], samples[splits[0]+splits[1]:]\n",
    "\n",
    "#given a single image and augmentation function, displays the image before and images after augmentation\n",
    "def visualizeAugmentation(img, aug):\n",
    "    #show original image\n",
    "    cv2.imshow('og', img)\n",
    "    cv2.waitKey(0)\n",
    "    #show all augmented images\n",
    "    for augmented in aug([(img, \"\")])[1:]:\n",
    "        cv2.imshow('augmented',augmented[0])\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "#given source dataset folder, loads all images and labels into arrays\n",
    "def loadInputData(source_folder):\n",
    "    samples = []\n",
    "    #get all filenames in the /images subfolder of given source_folder\n",
    "    img_filenames = [f for f in listdir(source_folder + '/images') if isfile(join(source_folder + '/images', f))]\n",
    "    for img_filename in img_filenames:\n",
    "        #load image at that filename\n",
    "        img = cv2.imread(source_folder + '/images/' + img_filename)\n",
    "        #got label filename corresponding to the image\n",
    "        label_filename = os.path.splitext(img_filename)[0] + \".txt\"\n",
    "        #load in the label file contents\n",
    "        with open(source_folder + \"/labels/\" + label_filename) as f:\n",
    "            #build array of bounding boxes (each line its own element)\n",
    "            bounding_boxes = []\n",
    "            for line in f.read().split(\"\\n\"):\n",
    "                bounding_boxes.append(line)\n",
    "        #add image and label to sample set\n",
    "        samples.append( (img, bounding_boxes) )\n",
    "    del img_filenames\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_names(source_folder):\n",
    "    label_filenames = []\n",
    "    img_filenames = [f for f in listdir(source_folder + '/images') if isfile(join(source_folder + '/images', f))]\n",
    "    for img_filename in img_filenames:\n",
    "        label_filenames.append(os.path.splitext(img_filename)[0] + \".txt\")\n",
    "\n",
    "    return np.array(img_filenames), np.array(label_filenames)\n",
    "\n",
    "def split_file_names(images,labels,splits):\n",
    "    perm = np.random.permutation(len(images))\n",
    "    images = images[perm]\n",
    "    labels = labels[perm]\n",
    "    splits = [int(len(images)*s) for s in splits]\n",
    "    train_images = images[:splits[0]]\n",
    "    train_labels = labels[:splits[0]]\n",
    "    val_images = images[splits[0]: splits[0] + splits[1]]\n",
    "    val_labels = labels[splits[0]: splits[0] + splits[1]]\n",
    "    test_images = images[splits[0] + splits[1]:]\n",
    "    test_labels = labels[splits[0] + splits[1]:]\n",
    "    return train_images, train_labels, val_images, val_labels, test_images, test_labels\n",
    "\n",
    "def get_augs(img_filename,source_folder):\n",
    "    img = cv2.imread(source_folder + '/images/' + img_filename)\n",
    "    prob = 0.5\n",
    "    augs = [img]\n",
    "    if(np.random.rand() > prob):\n",
    "        augs = augs + colorAugment([img])\n",
    "    if(np.random.rand() > prob):\n",
    "        augs = augs + brightnessAugment(augs)\n",
    "    if(np.random.rand() > prob):\n",
    "        augs = augs + contrastAugment(augs)\n",
    "    if(np.random.rand() > prob):\n",
    "        augs = augs + blurAugment(augs)\n",
    "    return augs\n",
    "\n",
    "def do_augs_and_export(img_filenames,label_filenames,source_folder,output_folder):\n",
    "    name_num = 1\n",
    "    for (img_filename,label_filename) in zip(img_filenames,label_filenames):\n",
    "        augs = get_augs(img_filename,source_folder)\n",
    "        with open(source_folder + \"/labels/\" + label_filename) as f:\n",
    "            #build array of bounding boxes (each line its own element)\n",
    "            bounding_boxes = f.read()\n",
    "        for aug in augs:\n",
    "            cv2.imwrite(output_folder + '/images/img' + str(name_num) + '.png', aug)\n",
    "            with open(output_folder + '/labels/img' + str(name_num) + '.txt',\"w+\") as f:\n",
    "                f.write(bounding_boxes)\n",
    "            name_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "\n",
    "rf = Roboflow(api_key=\"HV9jB1dcJZHZd1YO5S7C\") \n",
    "project = rf.workspace(\"comp400\").project(\"comp400-fish-detection\")\n",
    "dataset = project.version(1).download(\"yolov9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'sample_data': No such file or directory\n",
      "rm: cannot remove 'Front-cam-real-1': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "#Rename/move the images\n",
    "!rm -r sample_data\n",
    "!mv COMP400-Fish-detection-1/train/ dataset/raw\n",
    "!rm -r Front-cam-real-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_val_split = (0.7, 0.2, 0.1)\n",
    "out_folder = \"dataset/augmented\"\n",
    "in_folder = \"dataset/raw\"\n",
    "\n",
    "img_names, label_names = get_file_names(in_folder)\n",
    "train_images, train_labels, val_images, val_labels, test_images, test_labels = split_file_names(img_names,label_names,train_test_val_split)\n",
    "do_augs_and_export(train_images,train_labels,in_folder,out_folder + \"/train\")\n",
    "do_augs_and_export(val_images,val_labels,in_folder,out_folder + \"/val\")\n",
    "do_augs_and_export(test_images,test_labels,in_folder,out_folder + \"/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "#Ensure this prints true and a number > 0, if not make sure you set hardware accelerator to GPU in Edit > Notebook Settings > Hardware Accelerator\n",
    "# !rm -r runs/detect/train*\n",
    "!mkdir runs\n",
    "!mkdir runs/detect\n",
    "!mkdir runs/detect/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNCOMMENT TO START FROM SCRATCH\n",
    "torch.cuda.empty_cache()\n",
    "#model = YOLO(\"yolov8n.pt\")  # load a pretrained model\n",
    "#model = YOLO(\"runs/detect/train11/weights/last.pt\")\n",
    "# CONTINUE TRAINING\n",
    "model = YOLO(\"/content/best (3).pt\") #load a previous model in case training interrupts\n",
    "\n",
    "# Train the model in increments\n",
    "epoch_increments = 60\n",
    "# while True:\n",
    "model.train(data=\"data.yaml\", epochs=epoch_increments, device=0, batch=16, degrees=360, flipud=0.5, fliplr=0.5, perspective=0.001, translate=0.1, scale=0.3,mosaic=0.5,mixup=0.5, pretrained=True, task='detect')  # train the model\n",
    "model.val()\n",
    "#shutil.copyfile(\"runs/detect/train\" + str(i) + \"/weights/best.pt\", \"/content/drive/My Drive/AUV_model_\" + str(i) +"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
