{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install albumentations\n",
    "!pip install opencv-python\n",
    "!pip install ultralytics\n",
    "!pip install roboflow\n",
    "!pip install inference supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't have yolov9 set up\n",
    "!git clone https://github.com/SkalskiP/yolov9.git\n",
    "%cd yolov9\n",
    "!pip install -r requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you already have yolov9 in your repo\n",
    "%cd yolov9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from roboflow import Roboflow\n",
    "\n",
    "rf = Roboflow(api_key=\"HV9jB1dcJZHZd1YO5S7C\") \n",
    "project = rf.workspace(\"comp400\").project(\"comp400-fish-detection\")\n",
    "dataset = project.version(3).download(\"yolov9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train (training with on roboflow's website is easier - ignore this section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -P weights -q https://github.com/WongKinYiu/yolov9/releases/download/v0.1/yolov9-c.pt\n",
    "!wget -P weights -q https://github.com/WongKinYiu/yolov9/releases/download/v0.1/yolov9-e.pt\n",
    "!wget -P weights -q https://github.com/WongKinYiu/yolov9/releases/download/v0.1/gelan-c.pt\n",
    "!wget -P weights -q https://github.com/WongKinYiu/yolov9/releases/download/v0.1/gelan-e.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 train.py \\\n",
    "     --data COMP400-Fish-detection-3/data.yaml \\\n",
    "     --weights weights/gelan-c.pt \\\n",
    "     --cfg models/detect/gelan-c.yaml \\\n",
    "     --hyp hyp.scratch-high.yaml \\\n",
    "     --device cpu\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "\n",
    "rf = Roboflow(api_key='HV9jB1dcJZHZd1YO5S7C')\n",
    "project = rf.workspace('comp400').project('comp400-fish-detection')\n",
    "model = project.version(4).model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "data_dir = \"../data\"\n",
    "file_name = \"geo.txt\"\n",
    "\n",
    "with open(os.path.join(data_dir, file_name), \"r\") as f:\n",
    "     lines = f.readlines()\n",
    "     lines = lines[1:]  # Skip the header line\n",
    "\n",
    "filenames_raw, filenames_depth = [], []\n",
    "\n",
    "for line in lines:\n",
    "     filename_raw, filename_depth, _, _, _, _, _, _ = line.strip().split()\n",
    "     filenames_raw.append(filename_raw)\n",
    "     filenames_depth.append(filename_depth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'x': 176.0, 'y': 180.5, 'width': 104.0, 'height': 53.0, 'confidence': 0.8466671109199524, 'class': 'fish1', 'class_id': 0, 'detection_id': '04fd2e4e-4cf3-41f5-a46f-e102caf98bbe', 'image_path': '../data/00:31:39.171_raw.jpg', 'prediction_type': 'ObjectDetectionModel'}]\n",
      "[{'x': 183.0, 'y': 211.0, 'width': 118.0, 'height': 66.0, 'confidence': 0.891653299331665, 'class': 'fish1', 'class_id': 0, 'detection_id': '8928274e-54ee-48f2-9609-5f4c70acb711', 'image_path': '../data/00:31:52.171_raw.jpg', 'prediction_type': 'ObjectDetectionModel'}, {'x': 186.5, 'y': 64.0, 'width': 53.0, 'height': 36.0, 'confidence': 0.8373435735702515, 'class': 'fish1', 'class_id': 0, 'detection_id': '1a9df625-4067-490e-8760-c94d270ede70', 'image_path': '../data/00:31:52.171_raw.jpg', 'prediction_type': 'ObjectDetectionModel'}]\n",
      "[{'x': 205.0, 'y': 95.0, 'width': 44.0, 'height': 38.0, 'confidence': 0.8505633473396301, 'class': 'fish1', 'class_id': 0, 'detection_id': '7a939d7a-f8d8-449e-8150-e20110535525', 'image_path': '../data/00:31:58.171_raw.jpg', 'prediction_type': 'ObjectDetectionModel'}, {'x': 456.0, 'y': 256.0, 'width': 88.0, 'height': 50.0, 'confidence': 0.8010393977165222, 'class': 'fish1', 'class_id': 0, 'detection_id': '135a1d21-590c-455e-9dce-168e1de4fa07', 'image_path': '../data/00:31:58.171_raw.jpg', 'prediction_type': 'ObjectDetectionModel'}]\n",
      "[{'x': 380.0, 'y': 273.0, 'width': 42.0, 'height': 38.0, 'confidence': 0.7470335364341736, 'class': 'fish1', 'class_id': 0, 'detection_id': '7e7924f2-a884-49a4-83e3-a2f0c13321be', 'image_path': '../data/00:32:14.171_raw.jpg', 'prediction_type': 'ObjectDetectionModel'}]\n"
     ]
    }
   ],
   "source": [
    "with open(\"prediction.txt\", \"w\") as f:\n",
    "     f.write(\"filename_raw filename_depth x y width height\")\n",
    "     for i in range(len(filenames_raw)):\n",
    "          prediction = model.predict(os.path.join(data_dir, filenames_raw[i]), confidence=50, overlap=50).json()[\"predictions\"]\n",
    "          print(prediction)\n",
    "          for j in range(len(prediction)):\n",
    "               instance = prediction[j]\n",
    "               x = instance[\"x\"]\n",
    "               y = instance[\"y\"]\n",
    "               width = instance[\"width\"]\n",
    "               height = instance[\"height\"]\n",
    "               f.write(f\"\\n{filenames_raw[i]} {filenames_depth[i]} {x} {y} {width} {height}\")\n",
    "     \n",
    "     # uncoment next line if you want to visualize predictions\n",
    "     # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in filenames_raw:\n",
    "     predict = model.predict(os.path.join(data_dir, file), confidence=50, overlap=50).save(f\"prediction_{file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
