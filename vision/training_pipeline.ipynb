{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "\n",
    "rf = Roboflow(api_key='HV9jB1dcJZHZd1YO5S7C')\n",
    "project = rf.workspace('comp400').project('comp400-fish-detection')\n",
    "model = project.version(4).model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "data_dir = \"../data\"\n",
    "file_name = \"geo.txt\"\n",
    "\n",
    "with open(os.path.join(data_dir, file_name), \"r\") as f:\n",
    "     lines = f.readlines()\n",
    "     lines = lines[1:]  # Skip the header line\n",
    "\n",
    "filenames_raw, filenames_depth = [], []\n",
    "\n",
    "for line in lines:\n",
    "     filename_raw, filename_depth, _, _, _, _, _, _ = line.strip().split()\n",
    "     filenames_raw.append(filename_raw)\n",
    "     filenames_depth.append(filename_depth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'x': 516.0, 'y': 267.0, 'width': 168.0, 'height': 68.0, 'confidence': 0.8597159385681152, 'class': 'fish1', 'class_id': 0, 'detection_id': '47b6941e-d03a-4c53-90e4-b011084c65d5', 'image_path': '../data/05:41:50.171_raw.jpg', 'prediction_type': 'ObjectDetectionModel'}]\n",
      "[{'x': 191.0, 'y': 289.0, 'width': 86.0, 'height': 90.0, 'confidence': 0.890917181968689, 'class': 'fish1', 'class_id': 0, 'detection_id': '8fc29a62-13c9-4e9e-a6ab-c435623992d6', 'image_path': '../data/05:42:34.171_raw.jpg', 'prediction_type': 'ObjectDetectionModel'}]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "with open(\"prediction.txt\", \"w\") as f:\n",
    "     f.write(\"filename_raw filename_depth x y width height\")\n",
    "     for i in range(len(filenames_raw)):\n",
    "          prediction = model.predict(os.path.join(data_dir, filenames_raw[i]), confidence=50, overlap=50).json()[\"predictions\"]\n",
    "          print(prediction)               \n",
    "          for j in range(len(prediction)):\n",
    "               instance = prediction[j]\n",
    "               x = instance[\"x\"]\n",
    "               y = instance[\"y\"]\n",
    "               width = instance[\"width\"]\n",
    "               height = instance[\"height\"]\n",
    "               f.write(f\"\\n{filenames_raw[i]} {filenames_depth[i]} {x} {y} {width} {height}\")\n",
    "     \n",
    "     # uncoment next line if you want to visualize predictions\n",
    "     # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in filenames_raw:\n",
    "     predict = model.predict(os.path.join(data_dir, file), confidence=50, overlap=50).save(f\"prediction_{file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
